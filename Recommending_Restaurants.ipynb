{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "# traditional imports \n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import scipy as sp\n",
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl\n",
    "\n",
    "#colorbrewer2 Dark2 qualitative color table\n",
    "dark2_colors = [(0.10588235294117647, 0.6196078431372549, 0.4666666666666667),\n",
    "                (0.8509803921568627, 0.37254901960784315, 0.00784313725490196),\n",
    "                (0.4588235294117647, 0.4392156862745098, 0.7019607843137254),\n",
    "                (0.9058823529411765, 0.1607843137254902, 0.5411764705882353),\n",
    "                (0.4, 0.6509803921568628, 0.11764705882352941),\n",
    "                (0.9019607843137255, 0.6705882352941176, 0.00784313725490196),\n",
    "                (0.6509803921568628, 0.4627450980392157, 0.11372549019607843)]\n",
    "\n",
    "rcParams['figure.figsize'] = (10, 6)\n",
    "rcParams['figure.dpi'] = 150\n",
    "rcParams['axes.color_cycle'] = dark2_colors\n",
    "rcParams['lines.linewidth'] = 2\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "rcParams['font.size'] = 14\n",
    "rcParams['patch.edgecolor'] = 'white'\n",
    "rcParams['patch.facecolor'] = dark2_colors[0]\n",
    "rcParams['font.family'] = 'StixGeneral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_border(axes = None, left = True, bottom = True, right = False, top = False):\n",
    "    ax = axes or plt.gca()\n",
    "    ax.spines['top'].set_visible(top)\n",
    "    ax.spines['bottom'].set_visible(bottom)\n",
    "    ax.spines['right'].set_visible(right)\n",
    "    ax.spines['left'].set_visible(left)\n",
    "    \n",
    "    #turn off all ticks\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    \n",
    "    #now reenable them accordingily \n",
    "    \n",
    "    if top:\n",
    "        ax.xaxis.tick_top()\n",
    "    if bottom:\n",
    "        ax.xaxis.tick_bottom()\n",
    "    if left:\n",
    "        ax.yaxis.tick_left()\n",
    "    if right:\n",
    "        ax.yaxis.tick_right()\n",
    "        \n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "The data set has been extracted from the Yelp Phoenix restaurants dataset. The dataset is about the reviews, but the data of users and businesses has been joined.... so that we want to work on the single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'data/bigdf.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-966877c3be61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/bigdf.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'data/bigdf.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/bigdf.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c20975a52b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#we need a series object...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_user_revcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#bins is grouping on the x axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_user_revcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mremove_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#we need a series object...\n",
    "df_user_revcount = df.groupby('user_id').review_id.count()\n",
    "#bins is grouping on the x axis \n",
    "ax = df_user_revcount.hist(bins=50, log=True)  \n",
    "remove_border(ax)\n",
    "plt.xlabel(\"Reviews per user count\")\n",
    "plt.ylabel(\"No. of users giving this review count\")\n",
    "plt.grid(False)\n",
    "plt.grid(axis = 'y', color = 'white', linestyle = '-')\n",
    "plt.title(\"Revies per restaurant count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9222487f5842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_business_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_business_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mremove_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_business_count = df.groupby('business_id').review_id.count()\n",
    "ax = df_business_count.hist(bins = 50, log = True)\n",
    "remove_border(ax)\n",
    "plt.grid(False)\n",
    "plt.grid(axis = 'y', color = 'white', linestyle = '-')\n",
    "plt.xlabel(\"Reviews per business count\")\n",
    "plt.ylabel(\"No. of business getting this review count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7200ccccfe0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\"Users\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"businesses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\"Users\", len(df.user_id.unique()), \"businesses\", len(df.business_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are more users than businesses!\n",
    "\n",
    "What we see is intuitive, that is, less number of reviews are given be less users, very few users are kind of dedicated reviewing the movies, what we can extract is for example, users having more interest in the movies. Same goes for the number of businesses, but what we can extract is, the businesses having more number of reviews are less which tells us that there are very few businesses which are good or which may be have good approaches? \n",
    "\n",
    "Now we'll compute the average - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f2489235d4f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#mean revies given by the users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#mean revies given by the users\n",
    "df.stars.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8e96e18867b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#important plotting strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mremove_border\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Star rating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#important plotting strategy\n",
    "stars = df.stars \n",
    "ax=stars.hist(bins=5)\n",
    "remove_border(ax)\n",
    "plt.xlabel(\"Star rating\")\n",
    "plt.grid(False)\n",
    "plt.grid(axis = 'y', color ='white', linestyle='-')\n",
    "plt.title(\"Star ratings over all reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that most of the reviews are between 3.5 and 4 which is again, intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recompute_frame(ldf):\n",
    "    \"\"\"\n",
    "    takes a dataframe ldf, makes a copy of it, and returns the copy\n",
    "    with all averages and review counts recomputed\n",
    "    this is used when a frame is subsetted.\n",
    "    \"\"\"\n",
    "    ldfu=ldf.groupby('user_id')\n",
    "    ldfb=ldf.groupby('business_id')\n",
    "    user_avg=ldfu.stars.mean()\n",
    "    user_review_count=ldfu.review_id.count()\n",
    "    business_avg=ldfb.stars.mean()\n",
    "    business_review_count=ldfb.review_id.count()\n",
    "    #copy the dataframe\n",
    "    nldf=ldf.copy()\n",
    "    nldf.set_index(['business_id'], inplace=True)\n",
    "    nldf['business_avg']=business_avg\n",
    "    nldf['business_review_count']=business_review_count\n",
    "    nldf.reset_index(inplace=True)\n",
    "    nldf.set_index(['user_id'], inplace=True)\n",
    "    nldf['user_avg']=user_avg\n",
    "    nldf['user_review_count']=user_review_count\n",
    "    nldf.reset_index(inplace=True)\n",
    "    return nldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e1c29603f379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#smaller dataset meeting some of the conditions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msmallidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_review_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_review_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msmalldf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecompute_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmallidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#smaller dataset meeting some of the conditions \n",
    "smallidf = df[(df.user_review_count > 60) & (df.business_review_count > 150)]\n",
    "smalldf = recompute_frame(smallidf)\n",
    "smalldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smalldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-074108460bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'smalldf' is not defined"
     ]
    }
   ],
   "source": [
    "smalldf.user_id.unique().shape[0], smalldf.business_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of users and the number of businesses have drastically reduced which means that mostly the users tend to give less than total 60 reivies on the site... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smalldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c69ec61117d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#the mean hasn't changed much though\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smalldf' is not defined"
     ]
    }
   ],
   "source": [
    "smalldf.stars.mean()\n",
    "#the mean hasn't changed much though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smalldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-29a6064cbd8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#what we'll get is a less sparse histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#we need a series object...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msmalldf_user_revcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#bins is grouping on the x axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smalldf' is not defined"
     ]
    }
   ],
   "source": [
    "#what we'll get is a less sparse histogram\n",
    "#we need a series object...\n",
    "smalldf_user_revcount = smalldf.groupby('user_id').review_id.count()\n",
    "#bins is grouping on the x axis \n",
    "plt.figure()\n",
    "ax = smalldf_user_revcount.hist()  \n",
    "remove_border(ax)\n",
    "plt.xlabel(\"Reviews per user count\")\n",
    "plt.ylabel(\"No. of users giving this review count\")\n",
    "plt.grid(False)\n",
    "plt.grid(axis = 'y', color = 'white', linestyle = '-')\n",
    "plt.title(\"Revies per restaurant count\")\n",
    "plt.figure()\n",
    "smalldf_business_count = smalldf.groupby('business_id').business_review_count.count()\n",
    "ax = smalldf_business_count.hist()\n",
    "remove_border(ax)\n",
    "plt.grid(False)\n",
    "plt.grid(axis = 'y', color = 'white', linestyle = '-')\n",
    "plt.xlabel(\"Reviews per business count\")\n",
    "plt.ylabel(\"No. of business getting this review count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smalldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3b549e599fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavg_usr_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_usr_rating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mavg_business_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_business_rating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smalldf' is not defined"
     ]
    }
   ],
   "source": [
    "avg_usr_rating = smalldf.groupby('user_id').stars.mean()\n",
    "ax = avg_usr_rating.hist()\n",
    "plt.figure()\n",
    "avg_business_rating = smalldf.groupby('business_id').stars.mean()\n",
    "ax = avg_business_rating.hist()\n",
    "smalldf.stars.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smalldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-72c66d0aaea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrestaurants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmalldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msupports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestaurants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestaurants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smalldf' is not defined"
     ]
    }
   ],
   "source": [
    "restaurants = smalldf.business_id.unique()\n",
    "supports = []\n",
    "for i, rest1 in enumerate(restaurants):\n",
    "    for j, rest2 in enumerate(restaurants):\n",
    "        if i < j:\n",
    "            user_1 = smalldf[smalldf.business_id == rest1].user_id.unique()\n",
    "            user_2 = smalldf[smalldf.business_id == rest2].user_id.unique()\n",
    "            common_reviewers = set(user_1).intersection(user_2)\n",
    "            supports.append(len(common_reviewers))\n",
    "print (\"Mean support is:\",np.mean(supports))\n",
    "plt.hist(supports)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even though we chose a subset of the dataframe in which every restaurant had 150 reviews and every user had atleast made 60, the common support of most pairs of restaurants is really low, indeed less than 10!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Similarity\n",
    "\n",
    "What we are actually doing is calculating the similarity on the basis of to what degree the common users have rated the restaurants, and we do this by using the pearson's coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pearson coefficient or pearson product moment correlation(PPMC) is for measuring \n",
    "#the correlation between two variables is - covariance(X, Y) / std_dev(X) * std_dev(Y)\n",
    "from scipy.stats.stats import pearsonr\n",
    "def pearson_sim(rest1_reviews, rest2_reviews, n_common):\n",
    "    \"\"\"\n",
    "    Given a subframe of restaurant 1 reviews and a subframe of restaurant 2 reviews,\n",
    "    where the reviewers are those who have reviewed both restaurants, return \n",
    "    the pearson correlation coefficient between the user average subtracted ratings.\n",
    "    The case for zero common reviewers is handled separately. Its\n",
    "    ok to return a NaN if any of the individual variances are 0.\n",
    "    \"\"\"\n",
    "    if n_common==0:\n",
    "        rho=0.\n",
    "    else:\n",
    "        diff1=rest1_reviews['stars']-rest1_reviews['user_avg']\n",
    "        diff2=rest2_reviews['stars']-rest2_reviews['user_avg']\n",
    "        rho=pearsonr(diff1, diff2)[0]\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_restaurant_reviews(restaurant_id, df, set_of_users):\n",
    "    \"\"\"\n",
    "    given a resturant id and a set of reviewers, return the sub-dataframe of their\n",
    "    reviews.\n",
    "    \"\"\"\n",
    "    #isin returns a boolean matrix checking whether the values are in the \n",
    "    #dataframe or not.\n",
    "    #so get the users who have rated that business\n",
    "    mask = (df.user_id.isin(set_of_users)) & (df.business_id==restaurant_id)\n",
    "    reviews = df[mask]\n",
    "    #remove the duplicate items\n",
    "    reviews = reviews[reviews.user_id.duplicated()==False]\n",
    "    #return the cleaned dataframe\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for checking the degree of similarity between two restaurants  \n",
    "def calculate_similarity(rest1, rest2, df, similarity_func):\n",
    "    #get the users who have reviewed both the restaurants\n",
    "    users_rev_1 = df[df.business_id == rest1].user_id.unique()\n",
    "    users_rev_2 = df[df.business_id == rest2].user_id.unique()\n",
    "    users_inter = set(users_rev_1).intersection(users_rev_2)\n",
    "    #now get the subdataframes containing info about those users\n",
    "    get_rest1 = get_restaurant_reviews(rest1, df, users_inter)\n",
    "    get_rest2 = get_restaurant_reviews(rest2, df, users_inter)\n",
    "    #calculating the similarity using pearsons coefficient\n",
    "    calc_sim = similarity_func(get_rest1, get_rest2, len(get_rest1))\n",
    "    if np.isnan(calc_sim):\n",
    "        return (0, len(get_rest1))\n",
    "    return (calc_sim, len(get_rest1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20021785257950644, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing, testing 1..2..3..\n",
    "calculate_similarity(\"eIxSLxzIlfExI6vgAbn2JA\", \"bc-lE-wGVAsUrX-kJhtY-Q\", smalldf, pearson_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our functions are ready, now we'll create the database storing the pairwise similarity of all the restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a database of similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \"A class representing a database of similaries and common supports\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \"the constructor, takes a reviews dataframe like smalldf as its argument\"\n",
    "        database={}\n",
    "        self.df=df\n",
    "        self.uniquebizids={v:k for (k,v) in enumerate(df.business_id.unique())}\n",
    "        keys=self.uniquebizids.keys()\n",
    "        l_keys=len(keys)\n",
    "        self.database_sim=np.zeros([l_keys,l_keys])\n",
    "        self.database_sup=np.zeros([l_keys, l_keys], dtype=np.int)\n",
    "        \n",
    "    def populate_by_calculating(self, similarity_func):\n",
    "        \"\"\"\n",
    "        a populator for every pair of businesses in df. takes similarity_func like\n",
    "        pearson_sim as argument\n",
    "        \"\"\"\n",
    "        items=self.uniquebizids.items()\n",
    "        for b1, i1 in items:\n",
    "            for b2, i2 in items:\n",
    "                if i1 < i2:\n",
    "                    sim, nsup=calculate_similarity(b1, b2, self.df, similarity_func)\n",
    "                    self.database_sim[i1][i2]=sim\n",
    "                    self.database_sim[i2][i1]=sim\n",
    "                    self.database_sup[i1][i2]=nsup\n",
    "                    self.database_sup[i2][i1]=nsup\n",
    "                elif i1==i2:\n",
    "                    nsup=self.df[self.df.business_id==b1].user_id.count()\n",
    "                    self.database_sim[i1][i1]=1.\n",
    "                    self.database_sup[i1][i1]=nsup\n",
    "                    \n",
    "\n",
    "    def get(self, b1, b2):\n",
    "        \"returns a tuple of similarity,common_support given two business ids\"\n",
    "        sim=self.database_sim[self.uniquebizids[b1]][self.uniquebizids[b2]]\n",
    "        nsup=self.database_sup[self.uniquebizids[b1]][self.uniquebizids[b2]]\n",
    "        return (sim, nsup)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = Database(smalldf)\n",
    "db.populate_by_calculating(pearson_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39904554525734559, 7)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing....\n",
    "db.get(\"z3yFuLVrmH-3RJruPEMYKw\", \"zruUQvFySeXyEd7_rQixBg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest restaurants (in similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are again brought down to think like a bayesian... Think about the case in which there are 4 common reviewers and another case in which there are 40.In the former case, we might get a artificially high similarity based on the tastes of just this user, and thus we must reduce its importance in the nearest-neighbor calculation. In the latter case, we would get a much more unbiased estimator of the similarity of the two restaurants.\n",
    "\n",
    "So solve this problem we can shrink the PPMC(regilarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrunk_sim(sim, n_common, reg=3.):\n",
    "    \"takes a similarity and shrinks it down by using the regularizer\"\n",
    "    ssim=(n_common*sim)/(n_common+reg)\n",
    "    return ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def knearest(restaurant_id, set_of_restaurants, dbase, k = 3, reg = 3.):\n",
    "    sort_neighbors = []\n",
    "    for i in set_of_restaurants:\n",
    "        if i != restaurant_id:\n",
    "            #sim is the coefficient and nc is the number of common users \n",
    "            sim, nc = dbase.get(restaurant_id, i)\n",
    "            #regularisation\n",
    "            shrunken = shrunk_sim(sim, nc, reg = reg)\n",
    "            #putting in the list\n",
    "            sort_neighbors.append((i, shrunken, nc))\n",
    "    #print (sort_neighbors)        \n",
    "    similars = sorted(sort_neighbors, key=itemgetter(1), reverse=True)\n",
    "    return similars[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testbizid=\"eIxSLxzIlfExI6vgAbn2JA\"\n",
    "testbizid2=\"L-uPZxooP_ziXCtRrWi8Pw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def biznamefromid(df, theid):\n",
    "    return df['biz_name'][df['business_id']==theid].values[0]\n",
    "def usernamefromid(df, theid):\n",
    "    return df['user_name'][df['user_id']==theid].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eIxSLxzIlfExI6vgAbn2JA Lobbys Beef Burgers Dogs\n",
      "L-uPZxooP_ziXCtRrWi8Pw Café Monarch\n"
     ]
    }
   ],
   "source": [
    "print (testbizid, biznamefromid(smalldf,testbizid))\n",
    "print (testbizid2, biznamefromid(smalldf, testbizid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  Lobbys Beef Burgers Dogs , top matches are:\n",
      "0 La Condesa Gourmet Taco Shop | Sim 0.598714448434 | Support 6\n",
      "1 Citizen Public House | Sim 0.571428571429 | Support 4\n",
      "2 FnB | Sim 0.527129890943 | Support 5\n",
      "3 Defalco's Italian Grocery | Sim 0.519456555658 | Support 6\n",
      "4 Republic Ramen + Noodles | Sim 0.519140146937 | Support 5\n",
      "5 unPhogettable | Sim 0.5 | Support 3\n",
      "6 Haus Murphy's | Sim 0.467637235308 | Support 3\n"
     ]
    }
   ],
   "source": [
    "#the reason why I was not getting correct results was \n",
    "#that I had not set NaN to 0 in the database but why the error?\n",
    "tops=knearest(testbizid, smalldf.business_id.unique(), db, k=7, reg=3.)\n",
    "print (\"For \",biznamefromid(smalldf, testbizid), \", top matches are:\")\n",
    "for i, (biz_id, sim, nc) in enumerate(tops):\n",
    "    print (i,biznamefromid(smalldf,biz_id), \"| Sim\", sim, \"| Support\",nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  Café Monarch , top matches are:\n",
      "0 Postino Arcadia | Sim 0.625 | Support 5\n",
      "1 The Main Ingredient Ale House And Café | Sim 0.571428571429 | Support 4\n",
      "2 Brio Tuscan Grille | Sim 0.571428571429 | Support 4\n",
      "3 Kazimierz World Wine Bar | Sim 0.5 | Support 3\n",
      "4 Harlow's Cafe | Sim 0.5 | Support 3\n",
      "5 The Fry Bread House | Sim 0.5 | Support 3\n",
      "6 Cien Agaves Tacos & Tequila | Sim 0.5 | Support 3\n"
     ]
    }
   ],
   "source": [
    "tops2=knearest(testbizid2, smalldf.business_id.unique(), db, k=7, reg=3.)\n",
    "print (\"For \",biznamefromid(smalldf, testbizid2), \", top matches are:\")\n",
    "for i, (biz_id, sim, nc) in enumerate(tops2):\n",
    "    print (i,biznamefromid(smalldf,biz_id), \"| Sim\", sim, \"| Support\",nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zp713qNhx8d9KCJJnrw1xA'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######-----------TOTAL-SHIT------------######\n",
    "getbusid = smalldf[smalldf.biz_name == 'La Condesa Gourmet Taco Shop'].business_id.values[0]\n",
    "sim, nc = db.get(getbusid, testbizid)\n",
    "shrunk_sim(sim, nc)\n",
    "getbusid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user Vern top choices are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Tee Pee Mexican Food',\n",
       " 'Local Breeze',\n",
       " \"Carly's Bistro\",\n",
       " 'District American Kitchen and Wine Bar',\n",
       " 'Sonora Mesquite Grill']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_user_top_choices(user_id, df, numchoices=5):\n",
    "    \"get the sorted top 5 restaurants for a user by the star rating the user gave them\"\n",
    "    udf=df[df.user_id==user_id][['business_id','stars']].sort_values(by = 'stars', ascending=False).head(numchoices)\n",
    "    return udf\n",
    "testuserid=\"7cR92zkDv4W3kqzii6axvg\"\n",
    "print (\"For user\", usernamefromid(smalldf,testuserid), \"top choices are:\" )\n",
    "bizs=get_user_top_choices(testuserid, smalldf)['business_id'].values\n",
    "[biznamefromid(smalldf, biz_id) for biz_id in bizs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_recos_for_user(userid, df, dbase, n, k, reg = 3.):\n",
    "    #getting the top choices by that specific user \n",
    "    top_res_for_user = get_user_top_choices(userid, df)['business_id'].values\n",
    "    final_tops = []\n",
    "    rated_by_user=df[df.user_id==userid].business_id.values\n",
    "    for business in top_res_for_user:\n",
    "        knear = knearest(business, smalldf.business_id.unique(), db, k = 7, reg = 3.)\n",
    "        for i in knear:\n",
    "            if i[0] not in rated_by_user:\n",
    "                final_tops.append(i)\n",
    "    #getting the unique ids             \n",
    "    tops_bizids = [] \n",
    "    ids = [i[0] for i in final_tops]\n",
    "    uids = {k : 0 for k in list(set(ids))}\n",
    "    for j in final_tops:\n",
    "        if uids[j[0]] == 0:\n",
    "            tops_bizids.append(j)\n",
    "            uids[j[0]] == 1\n",
    "    tops = []\n",
    "    for biz_id, pr, ncom in tops_bizids:\n",
    "        biz_avg = df[df.business_id == biz_id].stars.mean()\n",
    "        tops.append((biz_id, biz_avg))\n",
    "    tops = sorted(tops, key = itemgetter(1), reverse = True)    \n",
    "    if n < len(tops):\n",
    "        return tops[0:n]\n",
    "    else:\n",
    "        return tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user Vern the top recommendations are:\n",
      "Rokerij | Average Rating | 4.37931034483\n",
      "Wildfish Seafood Grille | Average Rating | 4.29411764706\n",
      "Defalco's Italian Grocery | Average Rating | 4.23255813953\n",
      "Cornish Pasty Company | Average Rating | 4.20689655172\n",
      "Pappadeaux Seafood Kitchen | Average Rating | 4.18518518519\n"
     ]
    }
   ],
   "source": [
    "print (\"For user\", usernamefromid(smalldf,testuserid), \"the top recommendations are:\")\n",
    "toprecos=get_top_recos_for_user(testuserid, smalldf, db, n=5, k=7, reg=3.)\n",
    "for biz_id, biz_avg in toprecos:\n",
    "    print (biznamefromid(smalldf,biz_id), \"| Average Rating |\", biz_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this was a simple recommendation engine taking the info of what the user has rated and recommending using k neraest neighbors on the basis of pearson's coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A user based recommender with predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knearest_amongst_userrated(restaurant_id, user_id, df, dbase, k = 7, reg = 3.):\n",
    "    dfuser=df[df.user_id==user_id]\n",
    "    bizsuserhasrated=dfuser.business_id.unique()\n",
    "    return knearest(restaurant_id, bizsuserhasrated, dbase, k=k, reg=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rating(df, dbase, restaurant_id, user_id, k = 7, reg = 3.):\n",
    "    kn_users = knearest_amongst_userrated(restaurant_id, user_id, df, dbase, k = k, reg = reg)\n",
    "    #print (kn_users)\n",
    "    rest_mean = df[df.business_id == restaurant_id].business_avg.values[0]\n",
    "    user_mean = df[df.user_id == user_id].user_avg.values[0]\n",
    "    mu = df.stars.mean()\n",
    "    baseline = user_mean + rest_mean - mu\n",
    "    upscore = 0\n",
    "    score = 0\n",
    "    for id_, sim, ncom in kn_users:\n",
    "        score += sim\n",
    "        basln = df[(df.user_id == user_id) & (df.business_id == id_)].business_avg.values[0]\n",
    "        stars = df[(df.user_id == user_id) & (df.business_id == id_)].stars.values[0]\n",
    "        upscore += sim * (stars - (basln + user_mean - mu))\n",
    "    if score == 0:\n",
    "        return baseline\n",
    "    return baseline + upscore / score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Average 3.5652173913 for Vern\n",
      "Predicted ratings for top choices calculated earlier:\n",
      "Rokerij | 4.71714023074 | Average 4.37931034483\n",
      "Wildfish Seafood Grille | 4.27594504172 | Average 4.29411764706\n",
      "Defalco's Italian Grocery | 3.822223075 | Average 4.23255813953\n",
      "Cornish Pasty Company | 4.62810510121 | Average 4.20689655172\n",
      "Pappadeaux Seafood Kitchen | 4.08845573953 | Average 4.18518518519\n"
     ]
    }
   ],
   "source": [
    "print (\"User Average\", smalldf[smalldf.user_id==testuserid].stars.mean(),\"for\",usernamefromid(smalldf,testuserid))\n",
    "print (\"Predicted ratings for top choices calculated earlier:\")\n",
    "for biz_id,biz_avg in toprecos:\n",
    "    print (biznamefromid(smalldf, biz_id),\"|\",rating(smalldf, db, biz_id, testuserid, k=7, reg=3.),\"|\",\"Average\",biz_avg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major assumption in the approach above is **that we think that the user has rated quite a lot** but its not the case - \n",
    "\n",
    "1. What if the user has rated very few restuarants or he is quite new to the site?\n",
    "2. What if the restaurant is quite new?\n",
    "\n",
    "So should we think like a bayesian?? Hmm will look into it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_other_ratings(restaurant_id, user_id, df):\n",
    "    \"get a user's rating for a restaurant and the restaurant's average rating\"\n",
    "    choice=df[(df.business_id==restaurant_id) & (df.user_id==user_id)]\n",
    "    users_score=choice.stars.values[0]\n",
    "    average_score=choice.business_avg.values[0]\n",
    "    return users_score, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for user Vern avg 3.5652173913\n",
      "----------------------------------\n",
      "Tee Pee Mexican Food\n",
      "Predicted Rating: 3.52640184162\n",
      "Actual User Rating: 5 Avg Rating 3.04347826087\n",
      "----------------------------------\n",
      "Local Breeze\n",
      "Predicted Rating: 4.2280987611\n",
      "Actual User Rating: 5 Avg Rating 4.0\n",
      "----------------------------------\n",
      "Carly's Bistro\n",
      "Predicted Rating: 3.99008654065\n",
      "Actual User Rating: 5 Avg Rating 3.5\n",
      "----------------------------------\n",
      "District American Kitchen and Wine Bar\n",
      "Predicted Rating: 3.80281696528\n",
      "Actual User Rating: 4 Avg Rating 3.55263157895\n",
      "----------------------------------\n",
      "Sonora Mesquite Grill\n",
      "Predicted Rating: 4.08382083034\n",
      "Actual User Rating: 4 Avg Rating 4.38461538462\n"
     ]
    }
   ],
   "source": [
    "print (\"for user\",usernamefromid(smalldf,testuserid), 'avg', smalldf[smalldf.user_id==testuserid].stars.mean() )\n",
    "for biz_id in bizs:\n",
    "    print (\"----------------------------------\")\n",
    "    print (biznamefromid(smalldf, biz_id))\n",
    "    print (\"Predicted Rating:\",rating(smalldf, db, biz_id, testuserid, k=7, reg=3.) )\n",
    "    u,a=get_other_ratings(biz_id, testuserid, smalldf)\n",
    "    print (\"Actual User Rating:\",u,\"Avg Rating\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well here comes the devil. Bias-Variance Trade-off. Well, we are looking at the `bizs` which are the top rated rests by the user Vern which are the largest positive deviations from the mean. But in k nearest neighbors we are pooling info from all the info. Thus the predicted ratings fall closer to the mean rather than the true ones. \n",
    "\n",
    "In general, the larger K is (assuming that the similarities within this neighborhood are positive), the closer the predicted rating will be to Vern's user average (this is the bias limit in the bias-variance tradeoff). Similarly, the smaller K is, the more likely we are to have user ratings that are close to the observed rating (the variance limit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare_results(stars_actual, stars_predicted, ylow=-10, yhigh=15, title=\"\"):\n",
    "    \"\"\"\n",
    "    plot predicted results against actual results. Takes 2 arguments: a\n",
    "    numpy array of actual ratings and a numpy array of predicted ratings\n",
    "    scatterplots the predictions, a unit slope line, line segments joining the mean,\n",
    "    and a filled in area of the standard deviations.\"\n",
    "    \"\"\"\n",
    "    fig=plt.figure()\n",
    "    df=pd.DataFrame(dict(actual=stars_actual, predicted=stars_predicted))\n",
    "    #simple scatter plot, s is the size.\n",
    "    ax=plt.scatter(df.actual, df.predicted, alpha=0.2, s=30, label=\"predicted\")\n",
    "    plt.ylim([ylow,yhigh])\n",
    "    plt.plot([1,5],[1,5], label=\"slope 1\")\n",
    "    xp=[1,2,3,4,5]\n",
    "    #the mean of the predicted values correponding to 1-5\n",
    "    yp=df.groupby('actual').predicted.mean().values\n",
    "    plt.plot(xp,yp,'k', label=\"means\")\n",
    "    sig=df.groupby('actual').predicted.std().values\n",
    "    plt.fill_between(xp, yp - sig, yp + sig, \n",
    "                 color='k', alpha=0.2)\n",
    "    plt.xlabel(\"actual\")\n",
    "    plt.ylabel(\"predicted\")\n",
    "    plt.legend(frameon=False)\n",
    "    remove_border()\n",
    "    plt.grid(False)\n",
    "    plt.title(title)\n",
    "    print (\"fraction between -15 and 15 rating\", np.mean(np.abs(df.predicted) < 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_results_plot(df,k,reg):\n",
    "    uid=smalldf.user_id.values\n",
    "    bid=smalldf.business_id.values\n",
    "    actual=smalldf.stars.values\n",
    "    predicted=np.zeros(len(actual))\n",
    "    counter=0\n",
    "    for user_id, biz_id in zip(uid,bid):\n",
    "        predicted[counter]=rating(smalldf, db, biz_id, user_id, k=k, reg=reg) \n",
    "        counter=counter+1\n",
    "    compare_results(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, reg=3.\n",
      "fraction between -15 and 15 rating 0.997242497972\n",
      "k=3, reg=15.\n"
     ]
    }
   ],
   "source": [
    "print (\"k=3, reg=3.\")\n",
    "make_results_plot(smalldf,3,3.)\n",
    "plt.title(\"k=3, reg=3.\")\n",
    "\n",
    "print (\"k=3, reg=15.\")\n",
    "make_results_plot(smalldf,3,15.,)\n",
    "plt.title(\"k=3, reg=15.\")\n",
    "\n",
    "print (\"k=10, reg=3.\")\n",
    "make_results_plot(smalldf,10,3.)\n",
    "plt.title(\"k=10, reg=3.\")\n",
    "\n",
    "print (\"k=10, reg=15.\")\n",
    "make_results_plot(smalldf,10,15.,)\n",
    "plt.title(\"k=10, reg=15.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
