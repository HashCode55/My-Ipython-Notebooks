{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For us to estimate the best function or the model for prediction, the sample must be repreentative of the whole population....\n",
    "That is the error on the hypothesis must be the smallest and \n",
    "The out-sample-error or risk must be equal to the in-sample-risk, for which to happen, again the sample must be representative of the whole population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably after estimating the polynomial of degree 20 in the example given, we might say voila! lets go home, everything is fine, there minimimum bial or deterministic error and we can go home but no there is something else which can fuck up everything which is Noise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting to the noise causes overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire game is of predictive power!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error which came when we were trying to predict the sigmoidal function using a straight line was called bias but there is another error which comes in ml problems, which is variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which is the error associated with overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little discussion about scikit.learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing a 3rd degree polynomial fit on a sample of one feature for example, what scikit learn will do is raise them to the power equal to the degree of polynomial, rows representing the samples and columns as the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire machine learning is the game of minimizing the test error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make your model, fit your model, and then predict your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we divide the dataset in two different groups i.e. the test set and the training set, we train using particular group and then we contaminate it with another one, which we want to avoid, so what we do is we select a validation group in the training set and check on it, and to reduce the variance, we change the validation group and this process is known as cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
